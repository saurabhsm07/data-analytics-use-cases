{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Classificaion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries:\n",
    "import pandas as pd;    \n",
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing training and test data into pandas dataframe\n",
    "def import_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "def print_info(df):\n",
    "    return df.info()\n",
    "\n",
    "def print_description(df):\n",
    "    return df.describe()\n",
    "\n",
    "def print_head(df, count=5):\n",
    "    return df.head(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess both training and testing dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_mapper(df, column_name):\n",
    "    mapper = {}\n",
    "    data_list = df[column_name].unique()\n",
    "    data_list = ['missing' if pd.isnull(x) else x for x in data_list]\n",
    "    data_list.sort()\n",
    "    for i in range(0, len(data_list)):\n",
    "        if data_list[i] == 'missing':\n",
    "            mapper[np.nan] = 404\n",
    "        else:    \n",
    "            mapper[data_list[i]] = i\n",
    "    return mapper\n",
    "    \n",
    "def data_preprocessor(df):\n",
    " \n",
    "    df = (df.rename({'SibSp' : '# of Siblings', \n",
    "                                             'Parch': '# of Parents', \n",
    "                                             'Sex' : 'Gender',\n",
    "                                             'Pclass' : 'Class'},\n",
    "                                            axis = 1)\n",
    "                                    .drop(['Name', 'Ticket', 'PassengerId'], axis = 1)\n",
    "                                    .astype({'Gender' : pd.api.types.CategoricalDtype(df['Sex'].unique(), ordered=False), \n",
    "                                             'Class' : pd.api.types.CategoricalDtype(df['Pclass'].unique(), ordered=True)})\n",
    "#                                     .replace({'Embarked' : {np.NaN : 'un-known'}})\n",
    "                                    .replace({'Gender' : numeric_mapper(df, 'Sex'),\n",
    "                                              'Embarked' : numeric_mapper(df, 'Embarked'),\n",
    "                                              'Cabin' : numeric_mapper(df, 'Cabin'),\n",
    "                                              'Age' : {np.nan : 404}})\n",
    "                                    \n",
    "    #                                 .loc[:]\n",
    "                      )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing With Null Values In Attributes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 1 : Removing attributes with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In training only 2 attributes contains a major chunk of null data : Age and Cabin\n",
    "def drop_null_attributes(df):\n",
    "    df = (df.dropna(axis='columns')\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 2: Remove rows with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_rows(df):\n",
    "    df = (df.dropna(axis='rows')\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 3: Replacing null attribute values with mean, median or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nulls with averages \n",
    "def replace_null_with_mean(col):\n",
    "    if col.dtype.name == \"category\":\n",
    "        col = col.replace(np.nan,col.mode())\n",
    "    else:\n",
    "        col = col.replace(np.nan, col.mean())\n",
    "    return col\n",
    "\n",
    "def replace_nulls_phase_1(df):\n",
    "    df = (df.apply(replace_null_with_mean, axis = 0)\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 4: Group attributes with similar values and replace null values with mean or mode values of that specific group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return attributes with greatest correlation with the provided attribute\n",
    "def top_correlations(df,attribute, count = 2):\n",
    "    print(attribute)\n",
    "    correlations_df  = df.corr()\n",
    "    correlation_attribute = correlations_df[attribute]\n",
    "    correlation_attribute = correlation_attribute.to_frame()\n",
    "    correlation_attribute[attribute+'_mod'] = [ x if x > 0 else -1*x for x in correlations_df[attribute]]\n",
    "    return (correlation_attribute.sort_values(attribute+'_mod', ascending = False)[1: (count+1)].loc[:, attribute])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attribute with atleast 1 cell having a null value\n",
    "def get_attributes_with_nulls(df):\n",
    "    df_nulls = pd.Series(titanic_train_4.isna().any())\n",
    "    return df_nulls[df_nulls == True].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logistic_regression_model(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns!= 'Survived'], df['Survived'], test_size = 0.75, random_state = 0)\n",
    "    clf = LogisticRegression(solver = 'liblinear') #solver : liblinear good for small datasets\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cases :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = import_data(\"./../../../Datasets/Titanic/train.csv\");\n",
    "titanic_test =  import_data(\"./../../../Datasets/Titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing phase 1 for training and validation dataset\n",
    "titanic_train = data_preprocessor(titanic_train)\n",
    "print_head(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = data_preprocessor(titanic_test)\n",
    "print_head(titanic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed columns with null values\n",
    "titanic_train_1 = titanic_train.replace({404 : np.nan})\n",
    "titanic_train_1 = drop_null_attributes(titanic_train_1)\n",
    "create_logistic_regression_model(titanic_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed rows with null values\n",
    "titanic_train_2 = titanic_train.replace({404 : np.nan})\n",
    "titanic_train_2 = drop_null_rows(titanic_train_2)\n",
    "create_logistic_regression_model(titanic_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaced null values with mean and mode\n",
    "titanic_train_3 = titanic_train.replace({404 : np.nan})\n",
    "titanic_train_3 = replace_nulls_phase_1(titanic_train_3)\n",
    "create_logistic_regression_model(titanic_train_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_4 = (titanic_train.replace({404 : np.nan})\n",
    "                                .astype({'Class' : int})\n",
    "                  )\n",
    "titanic_train_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = titanic_train_4.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation[\"Age\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation[\"Age_mod\"] = [ x if x > 0 else -1*x for x in correlation[\"Age\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation[\"Age_mod\"].sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = top_correlations(titanic_train_4, 'Cabin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_attributes_with_nulls(titanic_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
