{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Survival Classificaion:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Imports :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required libraries:\n",
    "import pandas as pd;    \n",
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utility Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing training and test data into pandas dataframe\n",
    "def import_data(path):\n",
    "    return pd.read_csv(path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#utility functions\n",
    "def print_info(df):\n",
    "    return df.info()\n",
    "\n",
    "def print_description(df):\n",
    "    return df.describe()\n",
    "\n",
    "def print_head(df, count=5):\n",
    "    return df.head(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess both training and testing dataframe :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeric_mapper(df, column_name):\n",
    "    mapper = {}\n",
    "    data_list = df[column_name].unique()\n",
    "    data_list = ['missing' if pd.isnull(x) else x for x in data_list]\n",
    "    data_list.sort()\n",
    "    for i in range(0, len(data_list)):\n",
    "        if data_list[i] == 'missing':\n",
    "            mapper[np.nan] = 404\n",
    "        else:    \n",
    "            mapper[data_list[i]] = i\n",
    "    return mapper\n",
    "    \n",
    "def data_preprocessor(df):\n",
    " \n",
    "    df = (df.rename({'SibSp' : '# of Siblings', \n",
    "                                             'Parch': '# of Parents', \n",
    "                                             'Sex' : 'Gender',\n",
    "                                             'Pclass' : 'Class'},\n",
    "                                            axis = 1)\n",
    "                                    .drop(['Name', 'Ticket', 'PassengerId'], axis = 1)\n",
    "                                    .astype({'Gender' : pd.api.types.CategoricalDtype(df['Sex'].unique(), ordered=False), \n",
    "                                             'Class' : pd.api.types.CategoricalDtype(df['Pclass'].unique(), ordered=True)})\n",
    "#                                     .replace({'Embarked' : {np.NaN : 'un-known'}})\n",
    "                                    .replace({'Gender' : numeric_mapper(df, 'Sex'),\n",
    "                                              'Embarked' : numeric_mapper(df, 'Embarked'),\n",
    "                                              'Cabin' : numeric_mapper(df, 'Cabin'),\n",
    "                                              'Age' : {np.nan : 404}})\n",
    "                                    \n",
    "    #                                 .loc[:]\n",
    "                      )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing With Null Values In Attributes :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 1 : Removing attributes with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In training only 2 attributes contains a major chunk of null data : Age and Cabin\n",
    "def drop_null_attributes(df):\n",
    "    df = (df.dropna(axis='columns')\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 2: Remove rows with null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_rows(df):\n",
    "    df = (df.dropna(axis='rows')\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 3: Replacing null attribute values with mean, median or mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nulls with averages \n",
    "def replace_null_with_mean(col):\n",
    "    if col.dtype.name == \"category\":\n",
    "        col = col.replace(np.nan,col.mode())\n",
    "    else:\n",
    "        col = col.replace(np.nan, col.mean())\n",
    "    return col\n",
    "\n",
    "def replace_nulls_phase_1(df):\n",
    "    df = (df.apply(replace_null_with_mean, axis = 0)\n",
    "         )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CASE 4: Group attributes with similar values and replace null values with mean or mode values of that specific group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return attributes with greatest correlation with the provided attribute\n",
    "def top_correlations(df,attribute, count = 2):\n",
    "    correlations_df  = df.corr()\n",
    "    correlation_attribute = correlations_df[attribute]\n",
    "    correlation_attribute = correlation_attribute.to_frame()\n",
    "    correlation_attribute[attribute+'_mod'] = [ x if x > 0 else -1*x for x in correlations_df[attribute]]\n",
    "    return (correlation_attribute.sort_values(attribute+'_mod', ascending = False)[1: (count+1)].loc[:, attribute])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get attribute with atleast 1 cell having a null value\n",
    "def get_attributes_with_nulls(df):\n",
    "    df_nulls = pd.Series(titanic_train_4.isna().any())\n",
    "    return df_nulls[df_nulls == True].index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Models :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logistic_regression_model(df):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df.loc[:, df.columns!= 'Survived'], df['Survived'], test_size = 0.75, random_state = 0)\n",
    "    clf = LogisticRegression(solver = 'liblinear') #solver : liblinear good for small datasets\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Cases :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train = import_data(\"./../../../Datasets/Titanic/train.csv\");\n",
    "titanic_test =  import_data(\"./../../../Datasets/Titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing phase 1 for training and validation dataset\n",
    "titanic_train = data_preprocessor(titanic_train)\n",
    "print_head(titanic_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_test = data_preprocessor(titanic_test)\n",
    "print_head(titanic_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removed columns with null values\n",
    "titanic_train_1 = titanic_train.replace({404 : np.nan})\n",
    "titanic_train_1 = drop_null_attributes(titanic_train_1)\n",
    "create_logistic_regression_model(titanic_train_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removed rows with null values\n",
    "titanic_train_2 = titanic_train.replace({404 : np.nan})\n",
    "titanic_train_2 = drop_null_rows(titanic_train_2)\n",
    "create_logistic_regression_model(titanic_train_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replaced null values with mean and mode\n",
    "titanic_train_3 = titanic_train.replace({404 : np.nan})\n",
    "titanic_train_3 = replace_nulls_phase_1(titanic_train_3)\n",
    "create_logistic_regression_model(titanic_train_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Case 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_4 = (titanic_train.replace({404 : np.nan})\n",
    "                                .astype({'Class' : int})\n",
    "                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# form a dictionary structure of column with nulls as keys and attributes they are most correlated to as a list of values\n",
    "def get_top_corr_dict(attribute_with_nulls):\n",
    "    top_corr_dict = {}\n",
    "    for attribute in attribute_with_nulls:\n",
    "        top_corr_dict[attribute] = top_correlations(titanic_train_4, attribute)\n",
    "    return top_corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of values based on averages columns with null values based on groupby result of previous step\n",
    "def get_vals_based_on_corr_groups(top_corr_dict, attr_type):\n",
    "    values_based_corr_dict = {}\n",
    "    for attr in top_corr_dict.keys():\n",
    "        if attr_type[attr] == 'category':\n",
    "            df = titanic_train_4.groupby(top_corr_dict[attr].index.tolist(), as_index= False)[attr].agg(lambda x : x.value_counts().index[0] if len(x.value_counts()) is not 0 else titanic_train_4['Cabin'].value_counts().index[1])\n",
    "        else:\n",
    "            df = titanic_train_4.groupby(top_corr_dict[attr].index.tolist(),  as_index= False)[attr].agg(np.mean)\n",
    "        values_based_corr_dict[attr] = df \n",
    "    return values_based_corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute_with_nulls = get_attributes_with_nulls(titanic_train_4)\n",
    "top_corr_dict = get_top_corr_dict(attribute_with_nulls)\n",
    "\n",
    "attr_type = {'Age' : 'discrete', 'Cabin' : 'category', 'Embarked': 'category'}\n",
    "vals_based_on_corr_groups = get_vals_based_on_corr_groups(top_corr_dict, attr_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generalize below function update_null_vals for all attributes with null values, code before this function works fine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_null_vals(row, vals_based_on_corr_groups):\n",
    "    for attr in vals_based_on_corr_groups.keys():\n",
    "        if np.isnan(row[attr]):\n",
    "            if np.isnan(vals_based_on_corr_groups[attr].loc[row['Class']].loc[row['# of Siblings'], 'mean']):\n",
    "                row['Age'] = main_avg\n",
    "            else:\n",
    "                row['Age'] = vals_based_on_corr_groups.loc[row['Class']].loc[row['# of Siblings'], 'mean']\n",
    "    \n",
    "    return row\n",
    "\n",
    "titanic_train_4 = titanic_train_4.apply(update_null_vals, axis = 1, args= (vals_based_on_corr_groups, ));\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic_train_4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_corr_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals_based_on_corr_groups['Age'].loc[:,'Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Future Scope:\n",
    "\n",
    "- automate preprocessing end to end for all features\n",
    "- functional groupby for discrete values like \"Fare\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
